{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ff3638",
   "metadata": {},
   "source": [
    "# Cloud of emojis\n",
    "The following notebook will display all the emojis present in the comments as a cloud of emojis, where in the whole canvas, every single emoji will be placed randomly.\n",
    "\n",
    "This is a robust notebook that involves unexpectedly high complexity. This notebook works similarly to the cloud of words, but this time we will work with emojis only.\n",
    "This time we will not be using `WordCloud` to generate the cloud, since the library is not very friendly at handling emojis, it shows them rotated, with weird spacing, etc.\n",
    "\n",
    "Here, we will generate an image manually, and the library `Pillow` is perfect for this task.\n",
    "\n",
    "**Note**: The cloud of words uses information from enriched files, more specifically from the `tokens_wo_stopwords` column generated in the notebook `02_2_enriched_columns.ipynb`.\n",
    "If the enriched files don't exist, no information will be displayed, or it may fail.\n",
    "\n",
    "We start with our standard imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8214fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import polars as pl\n",
    "import cairosvg\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import config\n",
    "from paths import Paths\n",
    "from src.emoji_sampler import Sampler\n",
    "\n",
    "channel_paths = Paths(channel_handle=config.channel_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0d0e3",
   "metadata": {},
   "source": [
    "# Emoji frequencies\n",
    "In the word of cloud of words notebook we made use of the lazy framework from polars. Here we do the same, but for the emojis column on the enriched dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b48d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_emoji_counter(files: list[str], column: str = \"emojis\") -> Counter:\n",
    "    counter = Counter()\n",
    "\n",
    "    for path in tqdm(files, desc=\"Building word frequencies\"):\n",
    "        # Load the token column lazily\n",
    "        df = pl.read_parquet(path, columns=[column]).lazy()\n",
    "        \n",
    "        # Explode the list column (each token gets its own row)\n",
    "        df_exploded = df.explode(column)\n",
    "\n",
    "        # Drop nulls, just in case\n",
    "        df_filtered = df_exploded.drop_nulls(column)\n",
    "\n",
    "        # Count token frequencies\n",
    "        token_counts = (\n",
    "            df_filtered\n",
    "            .group_by(column)\n",
    "            .len()\n",
    "            .rename({column: \"emoji\", \"len\": \"count\"})\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "        # Update the global counter\n",
    "        counter.update(dict(zip(token_counts[\"emoji\"], token_counts[\"count\"])))\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b61258fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building word frequencies:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building word frequencies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 38.36it/s]\n"
     ]
    }
   ],
   "source": [
    "files = channel_paths.list_enriched_files()\n",
    "counter = build_emoji_counter(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c815bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1_390 distinct emojis, and a total of 1_116_387 total emojis.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are a total of {len(counter.keys()):_} distinct emojis, and a total of {sum(counter.values()):_} total emojis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5acdc8",
   "metadata": {},
   "source": [
    "## Cloud of emojis, SVG to Binary\n",
    "In order to make the cloud of emojis, we perform quite a technical process:\n",
    "1) Build the frequencies of emojis\n",
    "2) Sample a random emoji from the frequency table\n",
    "3) Get the SVG for the corresponding emoji\n",
    "4) Create the Image for this SVG, to place into the canvas\n",
    "5) Repeat from step 2) until all emojis have been sampled\n",
    "\n",
    "### SVG library\n",
    "The emojis used here are from the Twitter SVG Library [https://github.com/twitter/twemoji](https://github.com/twitter/twemoji), it is very complete, although there may be some missing emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOJI_SVG_FOLDER = os.path.join(\"..\", \"assets\", \"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fd3ea",
   "metadata": {},
   "source": [
    "## SVG to Image\n",
    "The advantage that this method provides is that we can essentially **generate an emoji of any size**, having only the svg. If we had a png file, if we enlarged the emoji it would get pixelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the codepoint of the emoji, so that it matches the assets/svg structure\n",
    "def emoji_to_codepoint(emoji):\n",
    "    return '-'.join(f\"{ord(char):x}\" for char in emoji)\n",
    "\n",
    "# Create image from the identified emoji\n",
    "def render_svg_to_image(emoji, size=96):\n",
    "\n",
    "    # Get the codepoint from the emoji\n",
    "    codepoint = emoji_to_codepoint(emoji)\n",
    "\n",
    "    # Path from codepoint\n",
    "    svg_path = os.path.join(EMOJI_SVG_FOLDER, f\"{codepoint}.svg\")\n",
    "    \n",
    "    # Emoji doesn't exist in the library\n",
    "    if not os.path.exists(svg_path):\n",
    "        print(f\"SVG not found for {emoji} at {svg_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Bytes to Image\n",
    "    png_bytes = cairosvg.svg2png(url=svg_path, output_width=size, output_height=size)\n",
    "    return Image.open(io.BytesIO(png_bytes)).convert('RGBA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df464e70",
   "metadata": {},
   "source": [
    "# Build image with table of frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a16c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_emoji_wordcloud(emoji_freq, image_size=(15360, 8640), output_file=\"emoji_svg_wordcloud.png\"):\n",
    "    canvas = Image.new('RGB', image_size, 'white')\n",
    "    seen_svgs = dict()\n",
    "    emoji_sampler = Sampler(emoji_freq)\n",
    "\n",
    "    for emoji in emoji_sampler:\n",
    "        if emoji in seen_svgs:\n",
    "            img = seen_svgs[emoji]\n",
    "        else:\n",
    "            img = render_svg_to_image(emoji, size=72)\n",
    "            seen_svgs[emoji] = img\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        x = random.randint(0, image_size[0] - img.width)\n",
    "        y = random.randint(0, image_size[1] - img.height)\n",
    "        canvas.paste(img, (x, y), img)  # Paste with alpha\n",
    "\n",
    "    canvas.save(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5f236",
   "metadata": {},
   "source": [
    "### Running the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d3294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVG not found for ðŸ©µ at ..\\assets\\svg\\1fa75.svg\n",
      "SVG not found for ðŸ«© at ..\\assets\\svg\\1fae9.svg\n",
      "SVG not found for ðŸ©· at ..\\assets\\svg\\1fa77.svg\n",
      "SVG not found for ðŸª¾ at ..\\assets\\svg\\1fabe.svg\n",
      "SVG not found for ðŸ«· at ..\\assets\\svg\\1faf7.svg\n",
      "SVG not found for ðŸ«¨ at ..\\assets\\svg\\1fae8.svg\n",
      "SVG not found for ðŸ›œ at ..\\assets\\svg\\1f6dc.svg\n",
      "SVG not found for ðŸ«š at ..\\assets\\svg\\1fada.svg\n",
      "SVG not found for ðŸ« at ..\\assets\\svg\\1facf.svg\n",
      "SVG not found for ðŸª¯ at ..\\assets\\svg\\1faaf.svg\n",
      "SVG not found for ðŸ©¶ at ..\\assets\\svg\\1fa76.svg\n",
      "SVG not found for ðŸ«œ at ..\\assets\\svg\\1fadc.svg\n",
      "SVG not found for ðŸª¼ at ..\\assets\\svg\\1fabc.svg\n",
      "SVG not found for ðŸ«¸ at ..\\assets\\svg\\1faf8.svg\n",
      "SVG not found for ðŸª½ at ..\\assets\\svg\\1fabd.svg\n",
      "SVG not found for ðŸª¿ at ..\\assets\\svg\\1fabf.svg\n",
      "SVG not found for ðŸ«› at ..\\assets\\svg\\1fadb.svg\n",
      "SVG not found for ðŸ«† at ..\\assets\\svg\\1fac6.svg\n",
      "SVG not found for ðŸª­ at ..\\assets\\svg\\1faad.svg\n",
      "SVG not found for ðŸª‡ at ..\\assets\\svg\\1fa87.svg\n",
      "SVG not found for ðŸª at ..\\assets\\svg\\1fa8f.svg\n",
      "SVG not found for ðŸ«Ž at ..\\assets\\svg\\1face.svg\n",
      "SVG not found for ðŸ«Ÿ at ..\\assets\\svg\\1fadf.svg\n",
      "SVG not found for ðŸª» at ..\\assets\\svg\\1fabb.svg\n",
      "SVG not found for ðŸª® at ..\\assets\\svg\\1faae.svg\n",
      "SVG not found for ðŸªˆ at ..\\assets\\svg\\1fa88.svg\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(channel_paths.results_dir, f\"{config.channel_handle}_emoji_svg_wordcloud.png\")\n",
    "size = (15360, 8640) # 4k\n",
    "draw_emoji_wordcloud(counter, image_size=size, output_file= output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youtube-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
